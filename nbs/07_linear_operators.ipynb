{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8832360d-b1aa-407f-9687-fba83222a08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp linops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d159edd4-4456-41f8-b520-8b1b69219c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import numpy as np\n",
    "import igl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f1cb15c-86cd-4e64-8f21-d4726216cd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.experimental.sparse as jsparse\n",
    "\n",
    "import lineax\n",
    "\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "723a50d1-f5c2-435c-9026-39b6067f426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from jaxtyping import Float "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cef3ff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from triangulax import trigonometry as trig\n",
    "from triangulax import mesh as msh\n",
    "from triangulax import adjacency as adj\n",
    "from triangulax import geometry as geom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "465aee96-fe0c-4994-97a5-d3ba628df4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "jax.config.update(\"jax_debug_nans\", False)\n",
    "jax.config.update('jax_log_compiles', False) # use this to log JAX JIT compilations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b39c35af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "import jaxtyping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5079edb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "%load_ext jaxtyping \n",
    "%jaxtyping.typechecker beartype.beartype\n",
    "\n",
    "# enables type checking. does not work for some cells (vmapping and loading/saving). For those, %unload_ext jaxtyping \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bffdeb3",
   "metadata": {},
   "source": [
    "## Finite-element gradient and cotan-Laplacian\n",
    "\n",
    "Building on the mesh geometry and adjancency-based operators, we can now define two important linear operators that depend both on mesh connectivity and on mesh geometry. They are the (discrete, triangulation-based) equivalent of the gradient and Laplace-Beltrami operator. The latter is known as the _cotan Laplacian_. \n",
    "\n",
    "We now implement gradient (per-vertex scalar field -> per-face vector field) and the cotan-Laplacian (vertex -> vertex) using gather/scatter ops. In both cases, we start with a scalar field $u_i$ defined per vertex $i$ of the triangulation. The finite-element gradient is defined for each face $ijk$, like so:\n",
    "$$ \n",
    "(\\nabla u)_{ijk} = \\sum_{l\\in \\{i,j,k\\}} u_l \\nabla\\phi_l\n",
    "$$\n",
    "where $\\phi_i$ is a linear finite element test function (linear Lagrange element) and has gradient\n",
    "$$\n",
    "    \\nabla\\phi_i = \\frac{1}{2a_{ijk}} (\\mathbf{v}_k-\\mathbf{v}_j)^\\perp\n",
    "$$\n",
    "plus cyclic permutations. Here, $a_{ijk}$ is the triangle area, $\\mathbf{v}_i$ are the vertex positions, and $()^\\perp$ denotes rotation by 90 degrees (in 3D, you rotate about the triangle normal).\n",
    "\n",
    "The cot-Laplacian computes the following per-vertex field:\n",
    "$$\n",
    "(\\Delta u)_i = \\frac{1}{2} \\sum_{j} (\\cot\\alpha_j +\\cot\\beta_j) (u_j-u_i)\n",
    "$$ \n",
    "where the sum is over adjacent vertices, and $\\alpha_j, \\beta_j$ are the two triangle angles \"opposite\" to the edge $ij$.\n",
    "\n",
    "To check for correctness, we can compare with [this `libgigl` tutorial](https://libigl.github.io/libigl-python-bindings/tut-chapter1/), using the test mesh and some random test fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e8eeb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from triangulax.triangular import TriMesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4006c7fb-56a2-445c-9647-017dc017074e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: readOBJ() ignored non-comment line 3:\n",
      "  o flat_tri_ecmc\n",
      "Warning: readOBJ() ignored non-comment line 3:\n",
      "  o flat_tri_ecmc\n"
     ]
    }
   ],
   "source": [
    "# load test data\n",
    "\n",
    "mesh = TriMesh.read_obj(\"test_meshes/disk.obj\")\n",
    "hemesh = msh.HeMesh.from_triangles(mesh.vertices.shape[0], mesh.faces)\n",
    "geommesh = msh.GeomMesh(*hemesh.n_items, mesh.vertices, mesh.face_positions)\n",
    "\n",
    "mesh_3d = TriMesh.read_obj(\"test_meshes/disk.obj\", dim=3)\n",
    "geommesh_3d = msh.GeomMesh(*hemesh.n_items, mesh_3d.vertices, mesh_3d.face_positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99259d8",
   "metadata": {},
   "source": [
    "### Cotan-Laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "66b2e04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def compute_cotan_laplace(vertices: Float[jax.Array, \"n_vertices dim\"], hemesh: msh.HeMesh,\n",
    "                          vertex_field: Float[jax.Array, \"n_vertices ...\"]\n",
    "                          ) -> Float[jax.Array, \"n_vertices ...\"]:\n",
    "    \"\"\"\n",
    "    Compute cotangent laplacian of a per-vertex field (natural boundary conditions).\n",
    "    \"\"\"\n",
    "    w_edge = geom.get_cotan_weights_per_egde(vertices, hemesh)\n",
    "    diff = vertex_field[hemesh.dest] - vertex_field[hemesh.orig]\n",
    "    return -adj.sum_he_to_vertex_incoming(hemesh, (w_edge*diff.T).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b9c6f5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def cotan_laplace_sparse(vertices: Float[jax.Array, \"n_vertices dim\"], hemesh: msh.HeMesh\n",
    "                         ) -> jsparse.BCOO:\n",
    "    \"\"\"Assemble cotangent Laplacian as a sparse matrix (BCOO).\"\"\"\n",
    "\n",
    "    w_edge = geom.get_cotan_weights_per_egde(vertices, hemesh)\n",
    "    unique = hemesh.is_unique\n",
    "\n",
    "    i = hemesh.orig[unique]\n",
    "    j = hemesh.dest[unique]\n",
    "    w = w_edge[unique]\n",
    "\n",
    "    rows = jnp.concatenate([i, j, i, j])\n",
    "    cols = jnp.concatenate([j, i, i, j])\n",
    "    data = jnp.concatenate([w, w, -w, -w])\n",
    "\n",
    "    mat = jsparse.BCOO((data, jnp.stack([rows, cols], axis=1)),\n",
    "                       shape=(hemesh.n_vertices, hemesh.n_vertices))\n",
    "    return mat.sum_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a781550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scalar field rel. error: 1.7692000627878292e-16\n",
      "vector field rel. error: 2.011929541056845e-16\n"
     ]
    }
   ],
   "source": [
    "# Test against libigl cotmatrix (natural boundary conditions)\n",
    "key = jax.random.PRNGKey(0)\n",
    "u = jax.random.normal(key, (hemesh.n_vertices,))\n",
    "u_vec = jax.random.normal(key, (hemesh.n_vertices, 3))\n",
    "\n",
    "L = igl.cotmatrix(np.asarray(geommesh.vertices), np.asarray(hemesh.faces))\n",
    "\n",
    "lap_jax = compute_cotan_laplace(geommesh.vertices, hemesh, u)\n",
    "lap_igl = L @ np.asarray(u)\n",
    "\n",
    "rel_err = np.linalg.norm(np.asarray(lap_jax) - lap_igl) / np.linalg.norm(lap_igl)\n",
    "print(\"scalar field rel. error:\", rel_err)\n",
    "\n",
    "lap_jax_vec = compute_cotan_laplace(geommesh.vertices, hemesh, u_vec)\n",
    "lap_igl_vec = L @ np.asarray(u_vec)\n",
    "\n",
    "rel_err_vec = np.linalg.norm(np.asarray(lap_jax_vec) - lap_igl_vec) / np.linalg.norm(lap_igl_vec)\n",
    "print(\"vector field rel. error:\", rel_err_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "95677f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cotan sparse vs apply rel. error: 1.302894564211555e-16\n"
     ]
    }
   ],
   "source": [
    "# test sparse cotan Laplacian vs apply function\n",
    "key = jax.random.PRNGKey(0)\n",
    "u_test = jax.random.normal(key, (hemesh.n_vertices,))\n",
    "\n",
    "L_sparse = cotan_laplace_sparse(geommesh.vertices, hemesh)\n",
    "lap_sparse = L_sparse @ u_test\n",
    "lap_apply = compute_cotan_laplace(geommesh.vertices, hemesh, u_test)\n",
    "\n",
    "rel_err_sparse = jnp.linalg.norm(lap_sparse - lap_apply) / jnp.linalg.norm(lap_apply)\n",
    "print(\"cotan sparse vs apply rel. error:\", rel_err_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2ca28f",
   "metadata": {},
   "source": [
    "### Finite-element gradient\n",
    "\n",
    "Not to be confused with the discrete-exterior-calculus operators, which only depend on mesh connectivity, not geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e2587568",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def _fe_grad_phi_2d(vertices: Float[jax.Array, \"n_vertices 2\"], hemesh: msh.HeMesh,\n",
    "                 ) -> Float[jax.Array, \"n_faces 3 2\"]:\n",
    "    \"\"\"Per-face gradients of the P1 hat functions (2D).\n",
    "\n",
    "    For each face f=(i,j,k), returns an array grads[f, l, :] = ∇φ_l, with l=0,1,2\n",
    "    corresponding to vertices (i,j,k). Degenerate faces get zero gradients.\n",
    "    \"\"\"\n",
    "    faces = hemesh.faces\n",
    "    v0, v1, v2 = (vertices[faces[:, 0]], vertices[faces[:, 1]], vertices[faces[:, 2]])\n",
    "\n",
    "    area2 = jnp.cross(v1 - v0, v2 - v0)[:, None]\n",
    "    mask = jnp.abs(area2) > 1e-12\n",
    "    grad_phi0 = jnp.where(mask, trig.get_perp_2d(v1 - v2)/area2, 0)\n",
    "    grad_phi1 = jnp.where(mask, trig.get_perp_2d(v2 - v0)/area2, 0)\n",
    "    grad_phi2 = jnp.where(mask, trig.get_perp_2d(v0 - v1)/area2, 0)\n",
    "\n",
    "    return jnp.stack([grad_phi0, grad_phi1, grad_phi2], axis=1)\n",
    "\n",
    "\n",
    "def _fe_grad_phi_3d(vertices: Float[jax.Array, \"n_vertices 3\"], hemesh: msh.HeMesh,\n",
    "                 ) -> Float[jax.Array, \"n_faces 3 3\"]:\n",
    "    \"\"\"Per-face gradients of the P1 hat functions (3D).\n",
    "\n",
    "    For each face f=(i,j,k), returns grads[f, l, :] = ∇φ_l in R^3, l=0,1,2.\n",
    "    Degenerate faces get zero gradients.\n",
    "    \"\"\"\n",
    "    faces = hemesh.faces\n",
    "    v0, v1, v2 = (vertices[faces[:, 0]], vertices[faces[:, 1]], vertices[faces[:, 2]])\n",
    "\n",
    "    n = jnp.cross(v1 - v0, v2 - v0)\n",
    "    area2 = jnp.linalg.norm(n, axis=-1)[:, None]**2\n",
    "    mask = area2 > 1e-12\n",
    "    \n",
    "    mask = jnp.abs(area2) > 1e-12\n",
    "    grad_phi0 = jnp.where(mask, jnp.cross(v1 - v2, n)/area2, 0)\n",
    "    grad_phi1 = jnp.where(mask, jnp.cross(v2 - v0, n)/area2, 0)\n",
    "    grad_phi2 = jnp.where(mask, jnp.cross(v0 - v1, n)/area2, 0)\n",
    "\n",
    "    return jnp.stack([grad_phi0, grad_phi1, grad_phi2], axis=1)\n",
    "\n",
    "\n",
    "def compute_gradient_2d(vertices: Float[jax.Array, \"n_vertices 2\"], hemesh: msh.HeMesh,\n",
    "                        vertex_field: Float[jax.Array, \"n_vertices ...\"]\n",
    "                        ) -> Float[jax.Array, \"n_faces 2 ...\"]:\n",
    "    \"\"\"Compute the linear finite-element gradient (constant per face).\"\"\"\n",
    "    faces = hemesh.faces\n",
    "    grads = _fe_grad_phi_2d(vertices, hemesh)\n",
    "    vals = vertex_field[faces]\n",
    "    return jnp.einsum(\"fvd,fv...->fd...\", grads, vals)\n",
    "\n",
    "\n",
    "def compute_gradient_3d(vertices: Float[jax.Array, \"n_vertices 3\"], hemesh: msh.HeMesh,\n",
    "                        vertex_field: Float[jax.Array, \"n_vertices ...\"]\n",
    "                        ) -> Float[jax.Array, \"n_faces 3 ...\"]:\n",
    "    \"\"\"Compute the linear finite-element gradient (constant per face).\"\"\"\n",
    "    faces = hemesh.faces\n",
    "    grads = _fe_grad_phi_3d(vertices, hemesh)\n",
    "    vals = vertex_field[faces]\n",
    "    return jnp.einsum(\"fvd,fv...->fd...\", grads, vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ebdd9818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def gradient_sparse_2d(vertices: Float[jax.Array, \"n_vertices 2\"], hemesh: msh.HeMesh,\n",
    "                      ) -> jsparse.BCOO:\n",
    "    \"\"\"Assemble FE gradient in 2D as a sparse matrix (BCOO).\n",
    "\n",
    "    Returns a matrix G with shape (2*n_faces, n_vertices) such that for a scalar\n",
    "    per-vertex field u (n_vertices,), the per-face gradients are obtained via:\n",
    "        g_flat = G @ u                    # (2*n_faces,)\n",
    "        g = g_flat.reshape((2, n_faces)).T  # (n_faces, 2)\n",
    "\n",
    "    This row layout matches libigl's `grad` operator convention (component blocks).\n",
    "    \"\"\"\n",
    "    faces = hemesh.faces.astype(jnp.int32)\n",
    "    n_faces = faces.shape[0]\n",
    "    n_vertices = hemesh.n_vertices\n",
    "\n",
    "    grads = _fe_grad_phi_2d(vertices, hemesh)  # (n_faces, 3, 2)\n",
    "    # order contributions as (component c, corner k, face f)\n",
    "    data = jnp.transpose(grads, (2, 1, 0)).reshape((-1,))  # (2*3*n_faces,)\n",
    "    cols_kf = faces.T.reshape((-1,))  # (3*n_faces,), order (k,f)\n",
    "    cols = jnp.tile(cols_kf, (2,))\n",
    "    rows_f = jnp.arange(n_faces, dtype=jnp.int32)\n",
    "    rows_kf = jnp.tile(rows_f, (3,))  # (3*n_faces,), order (k,f)\n",
    "    rows = jnp.tile(rows_kf, (2,)) + jnp.repeat(jnp.arange(2, dtype=jnp.int32) * n_faces, 3 * n_faces)\n",
    "\n",
    "    indices = jnp.stack([rows, cols], axis=1)\n",
    "    return jsparse.BCOO((data, indices), shape=(2 * n_faces, n_vertices))\n",
    "\n",
    "\n",
    "def gradient_sparse_3d(vertices: Float[jax.Array, \"n_vertices 3\"], hemesh: msh.HeMesh,\n",
    "                      ) -> jsparse.BCOO:\n",
    "    \"\"\"Assemble FE gradient in 3D as a sparse matrix (BCOO).\n",
    "\n",
    "    Returns a matrix G with shape (3*n_faces, n_vertices) such that for a scalar\n",
    "    per-vertex field u (n_vertices,), the per-face gradients are obtained via:\n",
    "        g_flat = G @ u                    # (3*n_faces,)\n",
    "        g = g_flat.reshape((3, n_faces)).T  # (n_faces, 3)\n",
    "\n",
    "    This row layout matches libigl's `grad` operator convention (component blocks).\n",
    "    \"\"\"\n",
    "    faces = hemesh.faces.astype(jnp.int32)\n",
    "    n_faces = faces.shape[0]\n",
    "    n_vertices = hemesh.n_vertices\n",
    "\n",
    "    grads = _fe_grad_phi_3d(vertices, hemesh)  # (n_faces, 3, 3)\n",
    "    data = jnp.transpose(grads, (2, 1, 0)).reshape((-1,))  # (3*3*n_faces,)\n",
    "    cols_kf = faces.T.reshape((-1,))  # (3*n_faces,)\n",
    "    cols = jnp.tile(cols_kf, (3,))\n",
    "    rows_f = jnp.arange(n_faces, dtype=jnp.int32)\n",
    "    rows_kf = jnp.tile(rows_f, (3,))\n",
    "    rows = jnp.tile(rows_kf, (3,)) + jnp.repeat(jnp.arange(3, dtype=jnp.int32) * n_faces, 3 * n_faces)\n",
    "\n",
    "    indices = jnp.stack([rows, cols], axis=1)\n",
    "    return jsparse.BCOO((data, indices), shape=(3 * n_faces, n_vertices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "86653c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def reshape_face_gradient(grad_flat: Float[jax.Array, \"dim_n_faces ...\"], n_faces: int, dim: int,\n",
    "                          ) -> Float[jax.Array, \"n_faces dim ...\"]:\n",
    "    \"\"\"Reshape a flattened FE gradient into per-face vectors.\n",
    "\n",
    "    This is meant to be used with `gradient_sparse_2d/3d` (and any similar operator that\n",
    "    stacks components in blocks), where applying the sparse matrix yields an array of shape\n",
    "    `(dim*n_faces, ...)` (for scalar/vector/tensor per-vertex fields).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    grad_flat\n",
    "        Output of `G @ u`, with shape `(dim*n_faces, ...)`.\n",
    "    n_faces\n",
    "        Number of mesh faces.\n",
    "    dim\n",
    "        Spatial dimension (2 or 3).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    grad\n",
    "        Reshaped gradient with shape `(n_faces, dim, ...)`, matching the output convention\n",
    "        of `compute_gradient_2d/3d`.\n",
    "    \"\"\"\n",
    "    if grad_flat.shape[0] != dim * n_faces:\n",
    "        raise ValueError(f\"Expected grad_flat.shape[0] == dim*n_faces = {dim*n_faces}, got {grad_flat.shape[0]}\")\n",
    "    grad = jnp.reshape(grad_flat, (dim, n_faces) + grad_flat.shape[1:])\n",
    "    return jnp.swapaxes(grad, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "92537afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's how to compute the gradient in libigl\n",
    "\n",
    "grad_matrix = igl.grad(np.asarray(geommesh.vertices), np.asarray(hemesh.faces))\n",
    "# calculate the gradient of field by matrix multiplication\n",
    "grad_igl = grad_matrix @ np.asarray(u)\n",
    "# order='F' copied from igl tutorial\n",
    "grad_igl = grad_igl.reshape((hemesh.n_faces, geommesh.dim), order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "58db395a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient rel. error: 1.413315746703021e-16\n"
     ]
    }
   ],
   "source": [
    "# test jax and libigl implementations\n",
    "\n",
    "grad_jax = compute_gradient_2d(geommesh.vertices, hemesh, u)\n",
    "\n",
    "rel_err_grad = np.linalg.norm(np.asarray(grad_jax) - grad_igl) / np.linalg.norm(grad_igl)\n",
    "print(\"gradient rel. error:\", rel_err_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fedbb5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient rel. error: 1.5657863888820882e-16\n"
     ]
    }
   ],
   "source": [
    "# same test, in 3d\n",
    "\n",
    "grad_matrix_3d = igl.grad(np.asarray(geommesh_3d.vertices), np.asarray(hemesh.faces))\n",
    "grad_igl_3d = grad_matrix_3d @ np.asarray(u)\n",
    "grad_igl_3d = grad_igl_3d.reshape((hemesh.n_faces, geommesh_3d.dim), order='F')\n",
    "\n",
    "grad_jax_3d = compute_gradient_3d(geommesh_3d.vertices, hemesh, u)\n",
    "\n",
    "rel_err_grad_3d = np.linalg.norm(np.asarray(grad_jax_3d) - grad_igl_3d) / np.linalg.norm(grad_igl_3d)\n",
    "print(\"gradient rel. error:\", rel_err_grad_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9ee1aaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D grad sparse vs apply rel. error: 8.71017994729607e-17\n",
      "3D grad sparse vs apply rel. error: 9.602668379845331e-17\n",
      "2D grad (vector field) sparse vs apply rel. error: 8.285943150518157e-17\n"
     ]
    }
   ],
   "source": [
    "# Test sparse gradient operators vs apply functions\n",
    "key = jax.random.PRNGKey(123)\n",
    "u_test = jax.random.normal(key, (hemesh.n_vertices,))\n",
    "\n",
    "G2 = gradient_sparse_2d(geommesh.vertices, hemesh)\n",
    "g2 = reshape_face_gradient(G2 @ u_test, hemesh.n_faces, dim=2)\n",
    "g2_apply = compute_gradient_2d(geommesh.vertices, hemesh, u_test)\n",
    "rel_err_g2 = jnp.linalg.norm(g2 - g2_apply) / jnp.linalg.norm(g2_apply)\n",
    "print(\"2D grad sparse vs apply rel. error:\", rel_err_g2)\n",
    "\n",
    "G3 = gradient_sparse_3d(geommesh_3d.vertices, hemesh)\n",
    "g3 = reshape_face_gradient(G3 @ u_test, hemesh.n_faces, dim=3)\n",
    "g3_apply = compute_gradient_3d(geommesh_3d.vertices, hemesh, u_test)\n",
    "rel_err_g3 = jnp.linalg.norm(g3 - g3_apply) / jnp.linalg.norm(g3_apply)\n",
    "print(\"3D grad sparse vs apply rel. error:\", rel_err_g3)\n",
    "\n",
    "# quick sanity check for vector/tensor fields: u has extra axes\n",
    "u_vec = jax.random.normal(key, (hemesh.n_vertices, 3))\n",
    "g2_vec = reshape_face_gradient(G2 @ u_vec, hemesh.n_faces, dim=2)\n",
    "g2_vec_apply = compute_gradient_2d(geommesh.vertices, hemesh, u_vec)\n",
    "rel_err_g2_vec = jnp.linalg.norm(g2_vec - g2_vec_apply) / jnp.linalg.norm(g2_vec_apply)\n",
    "print(\"2D grad (vector field) sparse vs apply rel. error:\", rel_err_g2_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0bc95a",
   "metadata": {},
   "source": [
    "### Wrapping as linear operators\n",
    "\n",
    "It's often useful to think of functions like `compute_cotan_laplace()` as a linear operator on fields on meshes. For example, imagine you want to solve the Laplace equation on a mesh with fixed vertex positions and connectivity. You will want to use a linear solver. Luckily, most such solvers only need to be able to compute the action of a linear operator on an input vector, and don't need an explicit matrix representation. \n",
    "\n",
    "In the JAX ecosystem, the `lineax` library defines linear solvers. We can _wrap_  `compute_cotan_laplace()` as a linear operator, which allows us to pass it into iterative linear algebra algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "16986532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def scipy_to_bcoo(A) -> jsparse.BCOO:\n",
    "    \"\"\"\n",
    "    Convert a SciPy sparse matrix (CSC or CSR) to a JAX BCOO sparse matrix\n",
    "    without converting to dense.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : scipy.sparse.spmatrix\n",
    "        Input sparse matrix (CSR or CSC recommended)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    B : jax.experimental.sparse.BCOO\n",
    "        Equivalent JAX sparse matrix\n",
    "    \"\"\"\n",
    "    # Convert to COO\n",
    "    Acoo = A.tocoo()\n",
    "\n",
    "    # COO format gives us row, col, data arrays directly\n",
    "    rows = jnp.array(Acoo.row, dtype=jnp.int32)\n",
    "    cols = jnp.array(Acoo.col, dtype=jnp.int32)\n",
    "    data = jnp.array(Acoo.data)\n",
    "    return jsparse.BCOO((data, jnp.stack([rows, cols], axis=1)), shape=Acoo.shape)\n",
    "\n",
    "\n",
    "def diag_jsparse(v : Float[jax.Array, \" N\"], k: int =0) -> jsparse.BCOO:\n",
    "    \"\"\"Construct a diagonal jax.sparse array. Plugin replacement for np.diag\"\"\"\n",
    "    N  = v.shape[0] + jnp.abs(k)\n",
    "    if k >=0:\n",
    "        row_inds = jnp.arange(k, N, dtype=jnp.int32)\n",
    "    else:\n",
    "        row_inds = jnp.arange(0, N+k, dtype=jnp.int32)\n",
    "    return jsparse.BCOO((v, jnp.stack([row_inds-k, row_inds,], axis=1)), shape=(N, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3b6f0ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%unload_ext jaxtyping \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ae8e6189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131, 131)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"bake in\" the connectivity and vertex positions\n",
    "\n",
    "laplace_op = functools.partial(compute_cotan_laplace, geommesh.vertices, hemesh)\n",
    "_ = laplace_op(u) # you can apply this to vertex-fields\n",
    "\n",
    "# define the linear operator\n",
    "laplace_op_lx = lineax.FunctionLinearOperator(laplace_op, input_structure=jax.eval_shape(laplace_op, u))\n",
    "\n",
    "# now you can use the linear operator to compute matrix representations, solve linear systems, etc.\n",
    "mat = laplace_op_lx.as_matrix()\n",
    "mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3d9366df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def linear_op_to_sparse(op: callable,\n",
    "                        in_shape: tuple[int, ...],\n",
    "                        out_shape: tuple[int, ...],\n",
    "                        dtype: jnp.dtype | None = None,\n",
    "                        chunk_size: int = 256,\n",
    "                        tol: float = 0.0,\n",
    "                        ) -> jsparse.BCOO:\n",
    "    \"\"\"Build a sparse matrix for a linear map using batched one-hot probes.\n",
    "\n",
    "    Note: this function is general, but not necessarily very efficient for large matrix sizes.\n",
    "    \"\"\"\n",
    "    if len(in_shape) != 1 or len(out_shape) != 1:\n",
    "        raise ValueError(\"Only 1D input/output supported for now.\")\n",
    "    n_in = in_shape[0]\n",
    "    n_out = out_shape[0]\n",
    "    if dtype is None:\n",
    "        dtype = jnp.result_type(op(jnp.zeros((n_in,))))\n",
    "\n",
    "    data_list: list[np.ndarray] = []\n",
    "    row_list: list[np.ndarray] = []\n",
    "    col_list: list[np.ndarray] = []\n",
    "\n",
    "    for start in range(0, n_in, chunk_size):\n",
    "        end = min(start + chunk_size, n_in)\n",
    "        idx = jnp.arange(start, end, dtype=jnp.int64)\n",
    "        basis = jax.nn.one_hot(jnp.array(idx), n_in, dtype=dtype)\n",
    "        cols = jax.vmap(op)(basis)  # (chunk, n_out)\n",
    "        #cols = apply_op(basis)\n",
    "        mask = jnp.abs(cols) > tol\n",
    "        col_in_batch, row_out = jnp.nonzero(mask)\n",
    "        if col_in_batch.size == 0:\n",
    "            continue\n",
    "\n",
    "        data_list.append(cols[col_in_batch, row_out])\n",
    "        row_list.append(row_out)\n",
    "        col_list.append(idx[col_in_batch])\n",
    "\n",
    "    if len(data_list) == 0:\n",
    "        return jsparse.empty((n_out, n_in)) \n",
    "    data = jnp.concatenate(data_list)\n",
    "    rows = jnp.concatenate(row_list)\n",
    "    cols = jnp.concatenate(col_list)\n",
    "    indices = jnp.stack([jnp.array(rows, dtype=jnp.int32),\n",
    "                            jnp.array(cols, dtype=jnp.int32)], axis=1)\n",
    "    return jsparse.BCOO((data, indices), shape=(n_out, n_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a9ed5a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse vs lineax rel. error: 0.0\n"
     ]
    }
   ],
   "source": [
    "# compare sparse construction to lineax dense matrix (small meshes only)\n",
    "if hemesh.n_vertices <= 2000:\n",
    "    laplace_op_local = functools.partial(compute_cotan_laplace, geommesh.vertices, hemesh)\n",
    "    laplace_op_lx_local = lineax.FunctionLinearOperator(laplace_op_local,\n",
    "                                                        input_structure=jax.eval_shape(laplace_op_local, u))\n",
    "    sp_mat = linear_op_to_sparse(laplace_op_local, (hemesh.n_vertices,), (hemesh.n_vertices,))\n",
    "    mat_dense = laplace_op_lx_local.as_matrix()\n",
    "    rel_err_sparse = jnp.linalg.norm(sp_mat.todense() - mat_dense) / jnp.linalg.norm(mat_dense)\n",
    "    print(\"sparse vs lineax rel. error:\", rel_err_sparse)\n",
    "else:\n",
    "    print(\"Skipping dense comparison for large mesh.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1cc5f280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: readOBJ() ignored non-comment line 3:\n",
      "  o Torus\n"
     ]
    }
   ],
   "source": [
    "## now let's try with a large mesh\n",
    "\n",
    "mesh = TriMesh.read_obj(\"test_meshes/torus_high_resolution.obj\")\n",
    "hemesh = msh.HeMesh.from_triangles(mesh.vertices.shape[0], mesh.faces)\n",
    "geommesh = msh.GeomMesh(*hemesh.n_items, mesh.vertices, mesh.face_positions)\n",
    "\n",
    "laplace_op = jax.jit(functools.partial(compute_cotan_laplace, geommesh.vertices, hemesh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "81a0ffb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_laplace_op = linear_op_to_sparse(laplace_op, (hemesh.n_vertices,), (hemesh.n_vertices,))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "triangulax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
